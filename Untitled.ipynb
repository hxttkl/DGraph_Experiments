{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.investigate import Missvalues\n",
    "from utils.investigate import Background\n",
    "from models import MLP, MLPLinear, GCN, SAGE, GAT, GATv2\n",
    "from logger import Logger\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.utils import to_undirected\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 17], edge_attr=[4300999], y=[3700550, 1], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=4300999])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "device = f'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "dataset = DGraphFin(root='./dataset/', name='DGraphFin', transform=T.ToSparseTensor())\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "\n",
    "data = dataset[0]\n",
    "print(data.coalesce())\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "x = data.x\n",
    "x = (x-x.mean())/x.std()\n",
    "data.x = x\n",
    "data.y = data.y.squeeze(1)        \n",
    "\n",
    "split_idx = {'train':data.train_mask, 'valid':data.valid_mask, 'test':data.test_mask}\n",
    "\n",
    "if split_idx['train'].dim()>1 and split_idx['train'].shape[1] >1:\n",
    "    kfolds = True\n",
    "    print('There are {} folds of splits'.format(split_idx['train'].shape[1]))\n",
    "    split_idx['train'] = split_idx['train'][:, fold]\n",
    "    split_idx['valid'] = split_idx['valid'][:, fold]\n",
    "    split_idx['test'] = split_idx['test'][:, fold]\n",
    "else:\n",
    "    kfolds = False\n",
    "\n",
    "missvalues = Missvalues('trickB')\n",
    "data = missvalues.process(data)\n",
    "\n",
    "print(data.edge_index)\n",
    "\n",
    "#BN = Background(args.BN_trick)\n",
    "#data = BN.process(data,args.BN_ratio)\n",
    "data.edge_index = data.adj_t\n",
    "data = data.to(device)\n",
    "train_idx = split_idx['train'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3700550, 34], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=4300999], edge_index=[3700550, 3700550, nnz=4300999])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = torch.cat([data.edge_index.coo()[0].view(1,-1),data.edge_index.coo()[1].view(1,-1)],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       1,       1,  ..., 3700548, 3700549, 3700549],\n",
       "        [ 146154, 1746169, 1752576,  ..., 2626653, 3249617, 3464387]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from typing import Callable, Optional, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.utils import remove_self_loops, degree, add_self_loops\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class MyConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        kwargs.setdefault('aggr', 'mean')\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        reset(self.nn)\n",
    "        self.eps.data.fill_(self.initial_eps)\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                size: Size = None) -> Tensor:\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor)\n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor,\n",
    "                              x: OptPairTensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x[0], reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(nn={self.nn})'\n",
    "class FeatureBlock(MessagePassing):\n",
    "    def __init__(self, aggr='add', **kwargs):\n",
    "        super(FeatureBlock, self).__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        h = x\n",
    "        h = self.propagate(edge_index, x=h, edge_weight=edge_weight)\n",
    "        return h\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        if edge_weight is not None:\n",
    "            return edge_weight.view(-1, 1) * x_j\n",
    "        return x_j\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, num_layers={})'.format(self.__class__.__name__,self.out_channels, self.num_layers)\n",
    "def label_norm(edge_index, num_nodes, edge_weight=None, improved=False,dtype=None):\n",
    "    if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,device=edge_index.device)\n",
    "    edge_index,edge_weight= remove_self_loops(edge_index,edge_weight)\n",
    "    row, col = edge_index\n",
    "    out_deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "    in_deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)\n",
    "    in_deg = in_deg+1e-9\n",
    "    out_deg = out_deg+1e-9\n",
    "    deg_inv_sqrt =1/(in_deg.sqrt())\n",
    "    deg_out_sqrt = 1/(out_deg.sqrt())\n",
    "    return edge_index,deg_inv_sqrt[col]*deg_out_sqrt[row]\n",
    "def label_norm1(edge_index, num_nodes, edge_weight=None, improved=False,dtype=None):\n",
    "    if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,device=edge_index.device)\n",
    "    edge_index,edge_weight= remove_self_loops(edge_index,edge_weight)\n",
    "    row, col = edge_index\n",
    "    out_deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "    in_deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)\n",
    "    print(col)\n",
    "    in_deg = in_deg+1e-9\n",
    "    out_deg = out_deg+1e-9\n",
    "    deg_inv_sqrt = 1/(in_deg.sqrt())\n",
    "    deg_out_sqrt = 1/(out_deg.sqrt())\n",
    "    return edge_index,deg_inv_sqrt[col]*deg_out_sqrt[row],in_deg.view(-1,1)\n",
    "\n",
    "class Label_Extract(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Label_Extract, self).__init__()\n",
    "        self.conv1 = FeatureBlock('add')\n",
    "        self.conv2 = FeatureBlock('add')\n",
    "    def forward(self, data,is_direct):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "        \n",
    "        label = data.label\n",
    "        x = label\n",
    "        edge_index, norm,in_degree = label_norm1(edge_index, x.shape[0],None, dtype=x.dtype)\n",
    "        edge_index1, norm1,out_degree = label_norm1(edge_index[[1,0],:], x.shape[0],None, dtype=x.dtype)\n",
    "        #norm_l = norm.view(-1,1)\n",
    "        #norm_r = norm1.view(-1,1)\n",
    "        h1 = self.conv1(x, edge_index[[1,0],:],norm1)\n",
    "        h2 = self.conv1(x,edge_index[[0,1],:],norm)\n",
    "        h3 = self.conv1(h2, edge_index[[1,0],:],norm1)\n",
    "        norm2 = norm*norm1\n",
    "        re = self.conv1(torch.ones((x.shape[0],1),dtype = torch.float), edge_index[[1,0],:],norm2)\n",
    "        print(re)\n",
    "        h3 -= label*re\n",
    "        #h3[h3<0.000001]-=h3[h3<0.000001]\n",
    "        \n",
    "        h4 = self.conv1(h1, edge_index[[0,1],:],norm)\n",
    "        norm2 = norm*norm1\n",
    "        re = self.conv1(torch.ones((x.shape[0],1),dtype = torch.float), edge_index[[0,1],:],norm2)\n",
    "        print(re.max())\n",
    "        h4 -= label*re\n",
    "        #h4[h4<0.000001]-=h4[h4<0.0000011]\n",
    "        \n",
    "        edge_index = tg.utils.to_undirected(edge_index)\n",
    "        edge_index = tg.utils.remove_self_loops(edge_index)[0]\n",
    "        #edge_weight = (edge_weight-edge_weight.min())/(edge_weight.max()-edge_weight.min()+1)\n",
    "        edge_index, norm= label_norm(edge_index, x.shape[0],None, dtype=x.dtype)\n",
    "        #edge_index2 = data.edge_index[[1,0],:]\n",
    "        xx = None\n",
    "        x1 = self.conv1(x, edge_index,norm)\n",
    "        x2 = self.conv1(x1,edge_index,norm)\n",
    "        re = self.conv1(torch.ones((x1.shape[0],1),dtype = torch.float), edge_index,norm*norm)\n",
    "        #x1 = self.conv1(x, edge_index,norm*norm)\n",
    "        x2 = x2 - label*re\n",
    "        x2 = x2/(x2.sum(dim=1).view(-1,1)+1e-5)\n",
    "        x1 = x1/(x1.sum(dim=1).view(-1,1)+1e-5)\n",
    "        h1 = h1/(h1.sum(dim=1).view(-1,1)+1e-5)\n",
    "        h2 = h2/(h2.sum(dim=1).view(-1,1)+1e-5)\n",
    "        h3 = h3/(h3.sum(dim=1).view(-1,1)+1e-5)\n",
    "        h4 = h4/(h4.sum(dim=1).view(-1,1)+1e-5)\n",
    "        return torch.cat([x2,x1,h3,h2,h1,h4],dim=1)\n",
    "def label_feature(data):\n",
    "    data = data.to('cpu')\n",
    "    y = torch.zeros(data.x.shape[0],4)\n",
    "    y[:,3]+=(data.y==3)\n",
    "    y[:,2]+=(data.y==2)\n",
    "    y[:,1]+=(data.y==1)\n",
    "    y[:,0]+=(data.y==0)\n",
    "    y[data.test_mask]-=y[data.test_mask]\n",
    "    #y[data.valid_mask]-=y[data.valid_mask]\n",
    "    conv=Label_Extract()\n",
    "    #data.edge_index = torch.cat([data.edge_index.coo()[0].view(1,-1),data.edge_index.coo()[1].view(1,-1)],dim=0)\n",
    "\n",
    "    data.label = y\n",
    "    y1 = conv(data,is_direct=False)\n",
    "    #x = torch.cat((y1,data.x),dim=1)\n",
    "    return y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 146154, 1746169, 1752576,  ..., 2626653, 3249617, 3464387])\n",
      "tensor([      0,       1,       1,  ..., 3700548, 3700549, 3700549])\n",
      "tensor([[0.2500],\n",
      "        [0.2917],\n",
      "        [0.3333],\n",
      "        ...,\n",
      "        [0.3333],\n",
      "        [0.2917],\n",
      "        [0.7500]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y1 = label_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       1,       1,  ..., 3700548, 3700549, 3700549],\n",
       "        [ 146154, 1746169, 1752576,  ..., 2626653, 3249617, 3464387]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.edge_index = tg.utils.to_undirected(data.edge_index)\n",
    "#h11 = conv(data.x,data.edge_index)\n",
    "#h12 = conv(data.x,data.edge_index[[1,0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h21 = conv(h11,data.edge_index[[1,0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h22 = conv(h12,data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to('cpu')\n",
    "x = torch.cat([data.x,y1],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = label_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([      0,       1,       1,  ..., 3700548, 3700549, 3700549]),\n",
       "             col=tensor([ 146154, 1746169, 1752576,  ..., 2626653, 3249617, 3464387]),\n",
       "             size=(3700550, 3700550), nnz=4300999, density=0.00%)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3700550, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3700550, 34], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=4300999], edge_index=[2, 4300999], label=[3700550, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_parameters = {'lr':0.01\n",
    "              , 'num_layers':2\n",
    "              , 'hidden_channels':64\n",
    "              , 'dropout':0.0\n",
    "              , 'batchnorm': False\n",
    "              , 'l2':5e-7\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('l2')\n",
    "model = MLP(in_channels = data.x.size(-1), out_channels = 2, **model_para).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x[list(data.train_mask.numpy())+list(data.valid_mask.numpy())].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.y[list(data.train_mask.numpy())+list(data.valid_mask.numpy())].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x[data.test_mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data.y[data.test_mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3700550, 58])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d4ee64867dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;31m#数值大没关系，cv会自动返回合适的n_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m xgb1 = XGBClassifier(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    " \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    " \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    " \n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    " \n",
    "n_estimators = 1000 #数值大没关系，cv会自动返回合适的n_estimators\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.3,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'multi:softprob',\n",
    "        seed=3)\n",
    " \n",
    "xgtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "xgb1.set_params(num_class = 3)\n",
    "        \n",
    "cvresult = xgb.cv(xgb1.get_xgb_params(), xgtrain, num_boost_round=n_estimators, folds =kfold,metrics='mlogloss', early_stopping_rounds=10)\n",
    "n_estimators = cvresult.shape[0]\n",
    " \n",
    " # 采用交叉验证得到的最佳参数n_estimators，训练模型\n",
    "xgb1.set_params(n_estimators = n_estimators)\n",
    "xgb1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set=16, n_jobs=-1 will be ignored. Current value: num_threads=16\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "(183840, 2)\n",
      "auc: 0.7940159371366042\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    #'objective': 'regression',\n",
    "    'objective':'binary',\n",
    "    # 'objective': 'cross_entropy',\n",
    "    #'num_class': 1,\n",
    "    'num_leaves':63,\n",
    "    # 'max_depth': 6,\n",
    "    'num_threads': 16,\n",
    "    'n_estimators':100,\n",
    "    #'min_data_in_leaf':1000,\n",
    "    'boosting':'gbdt',\n",
    "    'max_bin':10,\n",
    "    # 'device_type': 'gpu',\n",
    "    # 'gpu_device_id': 6,\n",
    "    'seed': 0,\n",
    "    #'min_split_gain': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'bagging_freq': 0,\n",
    "    'reg_lambda': 0.1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'learning_rate': 0.05,\n",
    "    'metric':'auc',\n",
    "    # 'min_child_samples': 1024,\n",
    "    # 'num_leaves': 127,\n",
    "    # 'learning_rate': 0.05,\n",
    "    'scale_pos_weight': 300\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
    " \n",
    "model=lgb.LGBMClassifier(**params)\n",
    "model.fit(X_train,y_train)\n",
    "y_pre=model.predict_proba(X_test)\n",
    "print(y_pre.shape)\n",
    "y_pre = y_pre[:,1]\n",
    "y_pre = y_pre.reshape(len(y_pre),1)\n",
    "import sklearn\n",
    "print(\"auc:\",sklearn.metrics.roc_auc_score(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4087848128807659"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设置参数\n",
      "交叉验证\n",
      "调参1：提高准确率\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xwhuang/.local/lib/python3.6/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-552e82f541ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                             )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    606\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                             eval_train_metric=eval_train_metric)\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# setup callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    359\u001b[0m                   shuffle=True, eval_train_metric=False):\n\u001b[1;32m    360\u001b[0m     \u001b[0;34m\"\"\"Make a n-fold list of Booster from random indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0mnum_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1820\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m   1665\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
    " \n",
    "### 设置初始参数--不含交叉验证参数\n",
    "print('设置参数')\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric': 'auc',\n",
    "          'nthread':4,\n",
    "          'learning_rate':0.1\n",
    "          }\n",
    " \n",
    "### 交叉验证(调参)\n",
    "print('交叉验证')\n",
    "max_auc = float('0')\n",
    "best_params = {}\n",
    " \n",
    "# 准确率\n",
    "print(\"调参1：提高准确率\")\n",
    "for num_leaves in range(5,100,5):\n",
    "    for max_depth in range(3,8,1):\n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_depth'] = max_depth\n",
    " \n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "            \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    "            \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc = mean_auc\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_depth'] = max_depth\n",
    "if 'num_leaves' and 'max_depth' in best_params.keys():          \n",
    "    params['num_leaves'] = best_params['num_leaves']\n",
    "    params['max_depth'] = best_params['max_depth']\n",
    " \n",
    "print(\"调参2：降低过拟合\")\n",
    "for max_bin in range(5,256,10):\n",
    "    for min_data_in_leaf in range(1,102,10):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc = mean_auc\n",
    "                best_params['max_bin']= max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "if 'max_bin' and 'min_data_in_leaf' in best_params.keys():\n",
    "    params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "    params['max_bin'] = best_params['max_bin']\n",
    " \n",
    "print(\"调参3：降低过拟合\")\n",
    "for feature_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "    for bagging_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "        for bagging_freq in range(0,50,5):\n",
    "            params['feature_fraction'] = feature_fraction\n",
    "            params['bagging_fraction'] = bagging_fraction\n",
    "            params['bagging_freq'] = bagging_freq\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc=mean_auc\n",
    "                best_params['feature_fraction'] = feature_fraction\n",
    "                best_params['bagging_fraction'] = bagging_fraction\n",
    "                best_params['bagging_freq'] = bagging_freq\n",
    " \n",
    "if 'feature_fraction' and 'bagging_fraction' and 'bagging_freq' in best_params.keys():\n",
    "    params['feature_fraction'] = best_params['feature_fraction']\n",
    "    params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "    params['bagging_freq'] = best_params['bagging_freq']\n",
    " \n",
    " \n",
    "print(\"调参4：降低过拟合\")\n",
    "for lambda_l1 in [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0]:\n",
    "    for lambda_l2 in [1e-5,1e-3,1e-1,0.0,0.1,0.4,0.6,0.7,0.9,1.0]:\n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "                \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc=mean_auc\n",
    "            best_params['lambda_l1'] = lambda_l1\n",
    "            best_params['lambda_l2'] = lambda_l2\n",
    "if 'lambda_l1' and 'lambda_l2' in best_params.keys():\n",
    "    params['lambda_l1'] = best_params['lambda_l1']\n",
    "    params['lambda_l2'] = best_params['lambda_l2']\n",
    " \n",
    "print(\"调参5：降低过拟合2\")\n",
    "for min_split_gain in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        seed=1,\n",
    "                        nfold=5,\n",
    "                        metrics=['auc'],\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose_eval=True\n",
    "                        )\n",
    "            \n",
    "    mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "    boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "    if mean_auc >= max_auc:\n",
    "        max_auc=mean_auc\n",
    "        \n",
    "        best_params['min_split_gain'] = min_split_gain\n",
    "if 'min_split_gain' in best_params.keys():\n",
    "    params['min_split_gain'] = best_params['min_split_gain']\n",
    " \n",
    "# print(best_params)\n",
    "\n",
    "# {'bagging_fraction': 0.7,\n",
    "#  'bagging_freq': 30,\n",
    "#  'feature_fraction': 0.8,\n",
    "#  'lambda_l1': 0.1,\n",
    "#  'lambda_l2': 0.0,\n",
    "#  'max_bin': 255,\n",
    "#  'max_depth': 4,\n",
    "#  'min_data_in_leaf': 81,\n",
    "#  'min_split_gain': 0.1,\n",
    "#  'num_leaves': 10}\n",
    "\n",
    "model=lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='auc',learning_rate=0.01, n_estimators=1000, max_depth=4, num_leaves=10,max_bin=255,min_data_in_leaf=81,bagging_fraction=0.7,bagging_freq= 30, feature_fraction= 0.8,\n",
    "lambda_l1=0.1,lambda_l2=0,min_split_gain=0.1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pre=model.predict(X_test)\n",
    "print(\"acc:\",metrics.accuracy_score(y_test,y_pre))\n",
    "print(\"auc:\",metrics.roc_auc_score(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1cef60c7f26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1131\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "y_pre=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3394\n",
      "Run: 01, Epoch: 10, Loss: 0.0696, Train AUC: 0.638 Train AP: 0.022 Valid AUC: 0.588 Valid AP: 0.015 Test AUC: 0.583 Test AP: 0.015\n",
      "Run: 01, Epoch: 20, Loss: 0.0884, Train AUC: 0.715 Train AP: 0.051 Valid AUC: 0.653 Valid AP: 0.019 Test AUC: 0.654 Test AP: 0.019\n",
      "Run: 01, Epoch: 30, Loss: 0.0722, Train AUC: 0.741 Train AP: 0.137 Valid AUC: 0.674 Valid AP: 0.021 Test AUC: 0.676 Test AP: 0.021\n",
      "Run: 01, Epoch: 40, Loss: 0.0626, Train AUC: 0.773 Train AP: 0.290 Valid AUC: 0.673 Valid AP: 0.021 Test AUC: 0.675 Test AP: 0.021\n",
      "Run: 01, Epoch: 50, Loss: 0.0568, Train AUC: 0.793 Train AP: 0.414 Valid AUC: 0.670 Valid AP: 0.023 Test AUC: 0.674 Test AP: 0.022\n",
      "Run: 01, Epoch: 60, Loss: 0.0536, Train AUC: 0.801 Train AP: 0.476 Valid AUC: 0.679 Valid AP: 0.023 Test AUC: 0.683 Test AP: 0.023\n",
      "Run: 01, Epoch: 70, Loss: 0.0486, Train AUC: 0.808 Train AP: 0.537 Valid AUC: 0.713 Valid AP: 0.029 Test AUC: 0.721 Test AP: 0.030\n",
      "Run: 01, Epoch: 80, Loss: 0.0452, Train AUC: 0.805 Train AP: 0.572 Valid AUC: 0.721 Valid AP: 0.030 Test AUC: 0.730 Test AP: 0.031\n",
      "Run: 01, Epoch: 90, Loss: 0.0430, Train AUC: 0.802 Train AP: 0.602 Valid AUC: 0.732 Valid AP: 0.032 Test AUC: 0.740 Test AP: 0.034\n",
      "Run: 01, Epoch: 100, Loss: 0.0417, Train AUC: 0.795 Train AP: 0.621 Valid AUC: 0.736 Valid AP: 0.034 Test AUC: 0.746 Test AP: 0.037\n",
      "Run: 01, Epoch: 110, Loss: 0.0409, Train AUC: 0.788 Train AP: 0.630 Valid AUC: 0.738 Valid AP: 0.035 Test AUC: 0.749 Test AP: 0.038\n",
      "Run: 01, Epoch: 120, Loss: 0.0405, Train AUC: 0.787 Train AP: 0.634 Valid AUC: 0.743 Valid AP: 0.036 Test AUC: 0.755 Test AP: 0.039\n",
      "Run: 01, Epoch: 130, Loss: 0.0402, Train AUC: 0.787 Train AP: 0.639 Valid AUC: 0.744 Valid AP: 0.037 Test AUC: 0.757 Test AP: 0.040\n",
      "Run: 01, Epoch: 140, Loss: 0.0400, Train AUC: 0.787 Train AP: 0.642 Valid AUC: 0.745 Valid AP: 0.037 Test AUC: 0.757 Test AP: 0.040\n",
      "Run: 01, Epoch: 150, Loss: 0.0398, Train AUC: 0.787 Train AP: 0.643 Valid AUC: 0.745 Valid AP: 0.037 Test AUC: 0.757 Test AP: 0.040\n",
      "Run: 01, Epoch: 160, Loss: 0.0395, Train AUC: 0.788 Train AP: 0.645 Valid AUC: 0.745 Valid AP: 0.038 Test AUC: 0.757 Test AP: 0.040\n",
      "Run: 01, Epoch: 170, Loss: 0.0393, Train AUC: 0.790 Train AP: 0.647 Valid AUC: 0.745 Valid AP: 0.038 Test AUC: 0.757 Test AP: 0.040\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ec015d0b742d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0meval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_ap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-47ac702a208b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data, split_idx, evaluator, no_conv)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGraph_Experiments/utils/evaluator.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_rocauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eval_rocauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGraph_Experiments/utils/evaluator.py\u001b[0m in \u001b[0;36m_eval_rocauc\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[1;32m    543\u001b[0m                                              max_fpr=max_fpr),\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0my_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_in_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \"\"\"\n\u001b[0;32m-> 2483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cumsum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_metric = 'auc'\n",
    "evaluator = Evaluator(eval_metric)\n",
    "#logger = Logger(5, args)\n",
    "no_conv = True  \n",
    "for run in range(5):\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    model.reset_parameters()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['l2'])\n",
    "    best_valid = 0\n",
    "    min_valid_loss = 1e8\n",
    "    best_out = None\n",
    "\n",
    "    for epoch in range(1, 400):\n",
    "        loss = train(model, data, train_idx, optimizer, no_conv)\n",
    "        eval_results, losses, out = test(model, data, split_idx, evaluator, no_conv)\n",
    "        train_auc, valid_auc, test_auc = eval_results['train']['auc'], eval_results['valid']['auc'], eval_results['test']['auc']\n",
    "        train_ap, valid_ap, test_ap = eval_results['train']['ap'], eval_results['valid']['ap'], eval_results['test']['ap']\n",
    "\n",
    "        train_loss, valid_loss, test_loss = losses['train'], losses['valid'], losses['test']\n",
    "        #print(eval_results['train'])\n",
    "#                 if valid_eval > best_valid:\n",
    "#                     best_valid = valid_result\n",
    "#                     best_out = out.cpu().exp()\n",
    "        if valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            best_out = out.cpu()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train AUC: {train_auc:.3f} '\n",
    "                      f'Train AP: {train_ap:.3f} '\n",
    "                      f'Valid AUC: {valid_auc:.3f} '\n",
    "                      f'Valid AP: {valid_ap:.3f} '\n",
    "                      f'Test AUC: { test_auc:.3f} '\n",
    "                      f'Test AP: { test_ap:.3f}')\n",
    "        #logger.add_result(run, [train_auc, valid_auc, test_auc])\n",
    "\n",
    "    #logger.print_statistics(run)\n",
    "\n",
    "final_results = logger.print_statistics()\n",
    "print('final_results:', final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, no_conv=False):\n",
    "    # data.y is labels of shape (N, ) \n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if no_conv:\n",
    "        out = model(data.x[train_idx])\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index)[train_idx]\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, no_conv=False):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    if no_conv:\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "    \n",
    "    losses, eval_results = dict(), dict()\n",
    "    for key in ['train', 'valid', 'test']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "        eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])\n",
    "            \n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
